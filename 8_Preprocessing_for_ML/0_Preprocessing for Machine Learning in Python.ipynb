{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Machine Learning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>vol_requests</th>\n",
       "      <th>event_time</th>\n",
       "      <th>title</th>\n",
       "      <th>hits</th>\n",
       "      <th>summary</th>\n",
       "      <th>is_priority</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_desc</th>\n",
       "      <th>...</th>\n",
       "      <th>end_date_date</th>\n",
       "      <th>status</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Community Council</th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>BIN</th>\n",
       "      <th>BBL</th>\n",
       "      <th>NTA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4996</td>\n",
       "      <td>37004</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Volunteers Needed For Rise Up &amp; Stay Put! Home...</td>\n",
       "      <td>737</td>\n",
       "      <td>Building on successful events last summer and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>July 30 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5008</td>\n",
       "      <td>37036</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Web designer</td>\n",
       "      <td>22</td>\n",
       "      <td>Build a website for an Afghan business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>February 01 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5016</td>\n",
       "      <td>37143</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
       "      <td>62</td>\n",
       "      <td>Please join us and the students from Mott Hall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>January 29 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5022</td>\n",
       "      <td>37237</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>Fight global hunger and support women farmers ...</td>\n",
       "      <td>14</td>\n",
       "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>...</td>\n",
       "      <td>March 31 2012</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5055</td>\n",
       "      <td>37425</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Stop 'N' Swap</td>\n",
       "      <td>31</td>\n",
       "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Environment</td>\n",
       "      <td>...</td>\n",
       "      <td>February 05 2011</td>\n",
       "      <td>approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   opportunity_id  content_id  vol_requests  event_time  \\\n",
       "0            4996       37004            50           0   \n",
       "1            5008       37036             2           0   \n",
       "2            5016       37143            20           0   \n",
       "3            5022       37237           500           0   \n",
       "4            5055       37425            15           0   \n",
       "\n",
       "                                               title  hits  \\\n",
       "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
       "1                                       Web designer    22   \n",
       "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
       "3  Fight global hunger and support women farmers ...    14   \n",
       "4                                      Stop 'N' Swap    31   \n",
       "\n",
       "                                             summary is_priority  category_id  \\\n",
       "0  Building on successful events last summer and ...         NaN          NaN   \n",
       "1             Build a website for an Afghan business         NaN          1.0   \n",
       "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
       "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
       "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
       "\n",
       "               category_desc ...     end_date_date    status Latitude  \\\n",
       "0                        NaN ...      July 30 2011  approved      NaN   \n",
       "1  Strengthening Communities ...  February 01 2011  approved      NaN   \n",
       "2  Strengthening Communities ...   January 29 2011  approved      NaN   \n",
       "3  Strengthening Communities ...     March 31 2012  approved      NaN   \n",
       "4                Environment ...  February 05 2011  approved      NaN   \n",
       "\n",
       "   Longitude  Community Board Community Council  Census Tract  BIN  BBL NTA  \n",
       "0        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "1        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "2        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "3        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "4        NaN              NaN                NaN          NaN  NaN  NaN NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "volunteer = pd.read_csv('volunteer_opportunities.csv')\n",
    "volunteer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(665, 35)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "opportunity_id          int64\n",
       "content_id              int64\n",
       "vol_requests            int64\n",
       "event_time              int64\n",
       "title                  object\n",
       "hits                    int64\n",
       "summary                object\n",
       "is_priority            object\n",
       "category_id           float64\n",
       "category_desc          object\n",
       "amsl                  float64\n",
       "amsl_unit             float64\n",
       "org_title              object\n",
       "org_content_id          int64\n",
       "addresses_count         int64\n",
       "locality               object\n",
       "region                 object\n",
       "postalcode            float64\n",
       "primary_loc           float64\n",
       "display_url            object\n",
       "recurrence_type        object\n",
       "hours                   int64\n",
       "created_date           object\n",
       "last_modified_date     object\n",
       "start_date_date        object\n",
       "end_date_date          object\n",
       "status                 object\n",
       "Latitude              float64\n",
       "Longitude             float64\n",
       "Community Board       float64\n",
       "Community Council     float64\n",
       "Census Tract          float64\n",
       "BIN                   float64\n",
       "BBL                   float64\n",
       "NTA                   float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strengthening Communities    307\n",
       "Helping Neighbors in Need    119\n",
       "Education                     92\n",
       "Health                        52\n",
       "Environment                   32\n",
       "Emergency Preparedness        15\n",
       "Name: category_desc, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer.category_desc.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strengthening Communities    230\n",
      "Helping Neighbors in Need     89\n",
      "Education                     69\n",
      "Health                        39\n",
      "Environment                   24\n",
      "Emergency Preparedness        11\n",
      "Name: category_desc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a data with all columns except category_desc\n",
    "volunteer_X = volunteer.drop('category_desc', axis=1)\n",
    "\n",
    "# Create a category_desc labels dataset\n",
    "volunteer_y = volunteer[['category_desc']]\n",
    "\n",
    "# Use stratified sampling to split up the dataset according to the volunteer_y dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(volunteer_X, volunteer_y, stratify=volunteer_y)\n",
    "\n",
    "# Print out the category_desc counts on the training y labels\n",
    "print(y_train['category_desc'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling without normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0     1    14.23        1.71  2.43               15.6        127   \n",
       "1     1    13.20        1.78  2.14               11.2        100   \n",
       "2     1    13.16        2.36  2.67               18.6        101   \n",
       "3     1    14.37        1.95  2.50               16.8        113   \n",
       "4     1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv('wine_types.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine.Type\n",
    "X = wine[['Proline', 'Total phenols', 'Hue', 'Nonflavanoid phenols']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type                                0.600679\n",
       "Alcohol                             0.659062\n",
       "Malic acid                          1.248015\n",
       "Ash                                 0.075265\n",
       "Alcalinity of ash                  11.152686\n",
       "Magnesium                         203.989335\n",
       "Total phenols                       0.391690\n",
       "Flavanoids                          0.997719\n",
       "Nonflavanoid phenols                0.015489\n",
       "Proanthocyanins                     0.327595\n",
       "Color intensity                     5.374449\n",
       "Hue                                 0.052245\n",
       "OD280/OD315 of diluted wines        0.504086\n",
       "Proline                         99166.717355\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Proline column has an extremely high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log normalization in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99166.71735542436\n",
      "0.17231366191842012\n"
     ]
    }
   ],
   "source": [
    "# Print out the variance of the Proline column\n",
    "print(wine.Proline.var())\n",
    "\n",
    "# Apply the log normalization function to the Proline column\n",
    "wine['Proline_log'] = np.log(wine.Proline)\n",
    "\n",
    "# Check the variance of the Proline column again\n",
    "print(wine.Proline_log.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    178.000000\n",
       "mean       2.366517\n",
       "std        0.274344\n",
       "min        1.360000\n",
       "25%        2.210000\n",
       "50%        2.360000\n",
       "75%        2.557500\n",
       "max        3.230000\n",
       "Name: Ash, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.Ash.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    178.000000\n",
       "mean      19.494944\n",
       "std        3.339564\n",
       "min       10.600000\n",
       "25%       17.200000\n",
       "50%       19.500000\n",
       "75%       21.500000\n",
       "max       30.000000\n",
       "Name: Alcalinity of ash, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['Alcalinity of ash'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    178.000000\n",
       "mean      99.741573\n",
       "std       14.282484\n",
       "min       70.000000\n",
       "25%       88.000000\n",
       "50%       98.000000\n",
       "75%      107.000000\n",
       "max      162.000000\n",
       "Name: Magnesium, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.Magnesium.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling data - standardizing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Import StandardScaler from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Take a subset of the DataFrame you want to scale \n",
    "wine_subset = wine[['Ash', 'Alcalinity of ash', 'Magnesium']]\n",
    "\n",
    "# Apply the scaler to the DataFrame subset\n",
    "wine_subset_scaled = ss.fit_transform(wine_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on non-scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('Type', axis=1)\n",
    "y = wine.Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('Proline_log', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset and labels into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN on scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "# Create the scaling method.\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply the scaling method to the dataset used for modeling.\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y)\n",
    "\n",
    "# Fit the k-nearest neighbors model to the training data.\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the test data.\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessible</th>\n",
       "      <th>Difficulty</th>\n",
       "      <th>Length</th>\n",
       "      <th>Limited_Access</th>\n",
       "      <th>Location</th>\n",
       "      <th>Name</th>\n",
       "      <th>Other_Details</th>\n",
       "      <th>Park_Name</th>\n",
       "      <th>Prop_ID</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>0.8 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
       "      <td>Salt Marsh Nature Trail</td>\n",
       "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
       "      <td>Marine Park</td>\n",
       "      <td>B057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>1.0 mile</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Lullwater</td>\n",
       "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.75 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Midwood</td>\n",
       "      <td>Step back in time with a walk through Brooklyn...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>Discover how the Peninsula has changed over th...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>Easy</td>\n",
       "      <td>0.5 miles</td>\n",
       "      <td>N</td>\n",
       "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
       "      <td>Waterfall</td>\n",
       "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
       "      <td>Prospect Park</td>\n",
       "      <td>B073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Accessible Difficulty      Length Limited_Access  \\\n",
       "0          Y       None   0.8 miles              N   \n",
       "1          N       Easy    1.0 mile              N   \n",
       "2          N       Easy  0.75 miles              N   \n",
       "3          N       Easy   0.5 miles              N   \n",
       "4          N       Easy   0.5 miles              N   \n",
       "\n",
       "                                            Location                     Name  \\\n",
       "0  Enter behind the Salt Marsh Nature Center, loc...  Salt Marsh Nature Trail   \n",
       "1  Enter Park at Lincoln Road and Ocean Avenue en...                Lullwater   \n",
       "2  Enter Park at Lincoln Road and Ocean Avenue en...                  Midwood   \n",
       "3  Enter Park at Lincoln Road and Ocean Avenue en...                Peninsula   \n",
       "4  Enter Park at Lincoln Road and Ocean Avenue en...                Waterfall   \n",
       "\n",
       "                                       Other_Details      Park_Name Prop_ID  \\\n",
       "0  <p>The first half of this mile-long trail foll...    Marine Park    B057   \n",
       "1  Explore the Lullwater to see how nature thrive...  Prospect Park    B073   \n",
       "2  Step back in time with a walk through Brooklyn...  Prospect Park    B073   \n",
       "3  Discover how the Peninsula has changed over th...  Prospect Park    B073   \n",
       "4  Trace the source of the Lake on the Waterfall ...  Prospect Park    B073   \n",
       "\n",
       "   lat  lon  \n",
       "0  NaN  NaN  \n",
       "1  NaN  NaN  \n",
       "2  NaN  NaN  \n",
       "3  NaN  NaN  \n",
       "4  NaN  NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiking = pd.read_json('hiking.json')\n",
    "hiking.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accessible  Accessible_enc\n",
      "0          Y               1\n",
      "1          N               0\n",
      "2          N               0\n",
      "3          N               0\n",
      "4          N               0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set up the LabelEncoder object\n",
    "enc = LabelEncoder()\n",
    "\n",
    "# Apply the encoding to the \"Accessible\" column\n",
    "hiking['Accessible_enc'] = enc.fit_transform(hiking['Accessible'])\n",
    "\n",
    "# Compare the two columns\n",
    "print(hiking[['Accessible', 'Accessible_enc']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables - one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Education  Emergency Preparedness  Environment  Health  \\\n",
      "0          0                       0            0       0   \n",
      "1          0                       0            0       0   \n",
      "2          0                       0            0       0   \n",
      "3          0                       0            0       0   \n",
      "4          0                       0            1       0   \n",
      "\n",
      "   Helping Neighbors in Need  Strengthening Communities  \n",
      "0                          0                          0  \n",
      "1                          0                          1  \n",
      "2                          0                          1  \n",
      "3                          0                          1  \n",
      "4                          0                          0  \n"
     ]
    }
   ],
   "source": [
    "# Transform the category_desc column\n",
    "category_enc = pd.get_dummies(volunteer['category_desc'])\n",
    "\n",
    "# Take a look at the encoded columns\n",
    "print(category_enc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - taking an average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the columns to average\n",
    "run_columns = ['run1', 'run2', 'run3', 'run4', 'run5']\n",
    "\n",
    "# Use apply to create a mean column\n",
    "running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n",
    "\n",
    "# Take a look at the results\n",
    "print(running_times_5k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering numerical features - datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_date_converted  start_date_month\n",
      "0           2011-07-30                 7\n",
      "1           2011-02-01                 2\n",
      "2           2011-01-29                 1\n",
      "3           2011-02-14                 2\n",
      "4           2011-02-05                 2\n"
     ]
    }
   ],
   "source": [
    "# First, convert string column to date column\n",
    "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer['start_date_date'])\n",
    "\n",
    "# Extract just the month from the converted column\n",
    "volunteer[\"start_date_month\"] = volunteer['start_date_converted'].apply(lambda row: row.month)\n",
    "\n",
    "# Take a look at the original and new columns\n",
    "print(volunteer[['start_date_converted', 'start_date_month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiking[\"Length\"].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Length  Length_num\n",
      "0   0.8 miles        0.80\n",
      "1    1.0 mile        1.00\n",
      "2  0.75 miles        0.75\n",
      "3   0.5 miles        0.50\n",
      "4   0.5 miles        0.50\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "# Write a pattern to extract numbers and decimals\n",
    "def return_mileage(length):\n",
    "    pattern = re.compile(\"\\d+\\.\\d+\")\n",
    "    \n",
    "    # Search the text for matches\n",
    "    mile = re.match(pattern, length)\n",
    "    \n",
    "    # If a value is returned, use group(0) to return the found value\n",
    "    if mile is not None:\n",
    "        return float(mile.group(0))\n",
    "        \n",
    "# Apply the function to the Length column and take a look at both columns\n",
    "hiking[\"Length_num\"] = hiking['Length'].apply(lambda row: return_mileage(row))\n",
    "print(hiking[[\"Length\", \"Length_num\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering features from strings - tf/idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "volunteer_drop = volunteer[['category_desc','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "volunteer_drop.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Take the title text\n",
    "title_text = volunteer_drop['title']\n",
    "\n",
    "# Create the vectorizer method\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# Transform the text into tf-idf vectors\n",
    "text_tfidf = tfidf_vec.fit_transform(title_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification using tf/idf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617, 1089)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset according to the class distribution of category_desc\n",
    "y = volunteer_drop[\"category_desc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5548387096774193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(text_tfidf.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print out the model's accuracy\n",
    "print(nb.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features for modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of redundant column names to drop\n",
    "to_drop = [\"category_desc\", \"created_date\", \"locality\", \"region\", \"vol_requests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_desc</th>\n",
       "      <th>created_date</th>\n",
       "      <th>locality</th>\n",
       "      <th>region</th>\n",
       "      <th>vol_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>January 13 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>January 14 2011</td>\n",
       "      <td>5 22nd St\\nNew York, NY 10010\\n(40.74053152272...</td>\n",
       "      <td>NY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>January 19 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strengthening Communities</td>\n",
       "      <td>January 21 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "      <td>January 28 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NY</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               category_desc     created_date  \\\n",
       "0                        NaN  January 13 2011   \n",
       "1  Strengthening Communities  January 14 2011   \n",
       "2  Strengthening Communities  January 19 2011   \n",
       "3  Strengthening Communities  January 21 2011   \n",
       "4                Environment  January 28 2011   \n",
       "\n",
       "                                            locality region  vol_requests  \n",
       "0                                                NaN     NY            50  \n",
       "1  5 22nd St\\nNew York, NY 10010\\n(40.74053152272...     NY             2  \n",
       "2                                                NaN     NY            20  \n",
       "3                                                NaN     NY           500  \n",
       "4                                                NaN     NY            15  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volunteer[to_drop].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   opportunity_id  content_id  event_time  \\\n",
      "0            4996       37004           0   \n",
      "1            5008       37036           0   \n",
      "2            5016       37143           0   \n",
      "3            5022       37237           0   \n",
      "4            5055       37425           0   \n",
      "\n",
      "                                               title  hits  \\\n",
      "0  Volunteers Needed For Rise Up & Stay Put! Home...   737   \n",
      "1                                       Web designer    22   \n",
      "2      Urban Adventures - Ice Skating at Lasker Rink    62   \n",
      "3  Fight global hunger and support women farmers ...    14   \n",
      "4                                      Stop 'N' Swap    31   \n",
      "\n",
      "                                             summary is_priority  category_id  \\\n",
      "0  Building on successful events last summer and ...         NaN          NaN   \n",
      "1             Build a website for an Afghan business         NaN          1.0   \n",
      "2  Please join us and the students from Mott Hall...         NaN          1.0   \n",
      "3  The Oxfam Action Corps is a group of dedicated...         NaN          1.0   \n",
      "4  Stop 'N' Swap reduces NYC's waste by finding n...         NaN          4.0   \n",
      "\n",
      "   amsl  amsl_unit       ...        Latitude  Longitude  Community Board  \\\n",
      "0   NaN        NaN       ...             NaN        NaN              NaN   \n",
      "1   NaN        NaN       ...             NaN        NaN              NaN   \n",
      "2   NaN        NaN       ...             NaN        NaN              NaN   \n",
      "3   NaN        NaN       ...             NaN        NaN              NaN   \n",
      "4   NaN        NaN       ...             NaN        NaN              NaN   \n",
      "\n",
      "   Community Council   Census Tract BIN BBL  NTA start_date_converted  \\\n",
      "0                 NaN           NaN NaN NaN  NaN           2011-07-30   \n",
      "1                 NaN           NaN NaN NaN  NaN           2011-02-01   \n",
      "2                 NaN           NaN NaN NaN  NaN           2011-01-29   \n",
      "3                 NaN           NaN NaN NaN  NaN           2011-02-14   \n",
      "4                 NaN           NaN NaN NaN  NaN           2011-02-05   \n",
      "\n",
      "  start_date_month  \n",
      "0                7  \n",
      "1                2  \n",
      "2                1  \n",
      "3                2  \n",
      "4                2  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop those columns from the dataset\n",
    "volunteer_subset = volunteer.drop(to_drop, axis=1)\n",
    "\n",
    "# Print out the head of the new dataset\n",
    "print(volunteer_subset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "      <th>Proline_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.633717</td>\n",
       "      <td>-0.569246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>0.637325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>-0.152643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>0.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>-0.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>-0.209179</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.424006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.431205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>-0.275675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.290203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color intensity</th>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.348970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.173593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <td>-0.788230</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>0.254218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>-0.633717</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline_log</th>\n",
       "      <td>-0.569246</td>\n",
       "      <td>0.637325</td>\n",
       "      <td>-0.152643</td>\n",
       "      <td>0.238394</td>\n",
       "      <td>-0.416897</td>\n",
       "      <td>0.424006</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>-0.275675</td>\n",
       "      <td>0.290203</td>\n",
       "      <td>0.348970</td>\n",
       "      <td>0.173593</td>\n",
       "      <td>0.254218</td>\n",
       "      <td>0.977423</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Type   Alcohol  Malic acid       Ash  \\\n",
       "Type                          1.000000 -0.328222    0.437776 -0.049643   \n",
       "Alcohol                      -0.328222  1.000000    0.094397  0.211545   \n",
       "Malic acid                    0.437776  0.094397    1.000000  0.164045   \n",
       "Ash                          -0.049643  0.211545    0.164045  1.000000   \n",
       "Alcalinity of ash             0.517859 -0.310235    0.288500  0.443367   \n",
       "Magnesium                    -0.209179  0.270798   -0.054575  0.286587   \n",
       "Total phenols                -0.719163  0.289101   -0.335167  0.128980   \n",
       "Nonflavanoid phenols          0.489109 -0.155929    0.292977  0.186230   \n",
       "Proanthocyanins              -0.499130  0.136698   -0.220746  0.009652   \n",
       "Color intensity               0.265668  0.546364    0.248985  0.258887   \n",
       "Hue                          -0.617369 -0.071747   -0.561296 -0.074667   \n",
       "OD280/OD315 of diluted wines -0.788230  0.072343   -0.368710  0.003911   \n",
       "Proline                      -0.633717  0.643720   -0.192011  0.223626   \n",
       "Proline_log                  -0.569246  0.637325   -0.152643  0.238394   \n",
       "\n",
       "                              Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "Type                                   0.517859  -0.209179      -0.719163   \n",
       "Alcohol                               -0.310235   0.270798       0.289101   \n",
       "Malic acid                             0.288500  -0.054575      -0.335167   \n",
       "Ash                                    0.443367   0.286587       0.128980   \n",
       "Alcalinity of ash                      1.000000  -0.083333      -0.321113   \n",
       "Magnesium                             -0.083333   1.000000       0.214401   \n",
       "Total phenols                         -0.321113   0.214401       1.000000   \n",
       "Nonflavanoid phenols                   0.361922  -0.256294      -0.449935   \n",
       "Proanthocyanins                       -0.197327   0.236441       0.612413   \n",
       "Color intensity                        0.018732   0.199950      -0.055136   \n",
       "Hue                                   -0.273955   0.055398       0.433681   \n",
       "OD280/OD315 of diluted wines          -0.276769   0.066004       0.699949   \n",
       "Proline                               -0.440597   0.393351       0.498115   \n",
       "Proline_log                           -0.416897   0.424006       0.431205   \n",
       "\n",
       "                              Nonflavanoid phenols  Proanthocyanins  \\\n",
       "Type                                      0.489109        -0.499130   \n",
       "Alcohol                                  -0.155929         0.136698   \n",
       "Malic acid                                0.292977        -0.220746   \n",
       "Ash                                       0.186230         0.009652   \n",
       "Alcalinity of ash                         0.361922        -0.197327   \n",
       "Magnesium                                -0.256294         0.236441   \n",
       "Total phenols                            -0.449935         0.612413   \n",
       "Nonflavanoid phenols                      1.000000        -0.365845   \n",
       "Proanthocyanins                          -0.365845         1.000000   \n",
       "Color intensity                           0.139057        -0.025250   \n",
       "Hue                                      -0.262640         0.295544   \n",
       "OD280/OD315 of diluted wines             -0.503270         0.519067   \n",
       "Proline                                  -0.311385         0.330417   \n",
       "Proline_log                              -0.275675         0.290203   \n",
       "\n",
       "                              Color intensity       Hue  \\\n",
       "Type                                 0.265668 -0.617369   \n",
       "Alcohol                              0.546364 -0.071747   \n",
       "Malic acid                           0.248985 -0.561296   \n",
       "Ash                                  0.258887 -0.074667   \n",
       "Alcalinity of ash                    0.018732 -0.273955   \n",
       "Magnesium                            0.199950  0.055398   \n",
       "Total phenols                       -0.055136  0.433681   \n",
       "Nonflavanoid phenols                 0.139057 -0.262640   \n",
       "Proanthocyanins                     -0.025250  0.295544   \n",
       "Color intensity                      1.000000 -0.521813   \n",
       "Hue                                 -0.521813  1.000000   \n",
       "OD280/OD315 of diluted wines        -0.428815  0.565468   \n",
       "Proline                              0.316100  0.236183   \n",
       "Proline_log                          0.348970  0.173593   \n",
       "\n",
       "                              OD280/OD315 of diluted wines   Proline  \\\n",
       "Type                                             -0.788230 -0.633717   \n",
       "Alcohol                                           0.072343  0.643720   \n",
       "Malic acid                                       -0.368710 -0.192011   \n",
       "Ash                                               0.003911  0.223626   \n",
       "Alcalinity of ash                                -0.276769 -0.440597   \n",
       "Magnesium                                         0.066004  0.393351   \n",
       "Total phenols                                     0.699949  0.498115   \n",
       "Nonflavanoid phenols                             -0.503270 -0.311385   \n",
       "Proanthocyanins                                   0.519067  0.330417   \n",
       "Color intensity                                  -0.428815  0.316100   \n",
       "Hue                                               0.565468  0.236183   \n",
       "OD280/OD315 of diluted wines                      1.000000  0.312761   \n",
       "Proline                                           0.312761  1.000000   \n",
       "Proline_log                                       0.254218  0.977423   \n",
       "\n",
       "                              Proline_log  \n",
       "Type                            -0.569246  \n",
       "Alcohol                          0.637325  \n",
       "Malic acid                      -0.152643  \n",
       "Ash                              0.238394  \n",
       "Alcalinity of ash               -0.416897  \n",
       "Magnesium                        0.424006  \n",
       "Total phenols                    0.431205  \n",
       "Nonflavanoid phenols            -0.275675  \n",
       "Proanthocyanins                  0.290203  \n",
       "Color intensity                  0.348970  \n",
       "Hue                              0.173593  \n",
       "OD280/OD315 of diluted wines     0.254218  \n",
       "Proline                          0.977423  \n",
       "Proline_log                      1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "labels ['Flavanoids'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-55cb496851c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Drop that column from the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Flavanoids'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# Print out the column correlations of the wine dataset\n",
    "display(wine.corr())\n",
    "\n",
    "# Take a minute to find the column where the correlation value is greater than 0.75 at least twice\n",
    "to_drop = \"Flavanoids\"\n",
    "\n",
    "# Drop that column from the DataFrame\n",
    "wine = wine.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {v:k for k,v in tfidf_vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189, 942, 466]\n"
     ]
    }
   ],
   "source": [
    "# Add in the rest of the parameters\n",
    "def return_weights(vocab, original_vocab, vector, vector_index, top_n):\n",
    "    zipped = dict(zip(vector[vector_index].indices, vector[vector_index].data))\n",
    "    \n",
    "    # Let's transform that zipped dict into a series\n",
    "    zipped_series = pd.Series({vocab[i]:zipped[i] for i in vector[vector_index].indices})\n",
    "    \n",
    "    # Let's sort the series to pull out the top n weighted words\n",
    "    zipped_index = zipped_series.sort_values(ascending=False)[:top_n].index\n",
    "    \n",
    "    return [original_vocab[i] for i in zipped_index]\n",
    "\n",
    "# Print out the weighted words\n",
    "print(return_weights(vocab, tfidf_vec.vocabulary_, text_tfidf, 8, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([498, 942, 189, 466, 717, 409], dtype=int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf[8].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf[8].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1089)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf[8].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23125626, 0.40223995, 0.67322092, 0.37801806, 0.27439553,\n",
       "       0.33661046])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_tfidf[8].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring text vectors, part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_to_filter(vocab, original_vocab, vector, top_n):\n",
    "    filter_list = []\n",
    "    for i in range(0, vector.shape[0]):\n",
    "    \n",
    "        # Here we'll call the function from the previous exercise, and extend the list we're creating\n",
    "        filtered = return_weights(vocab, original_vocab, vector, i, top_n)\n",
    "        filter_list.extend(filtered)\n",
    "    # Return the list in a set, so we don't get duplicate word indices\n",
    "    return set(filter_list)\n",
    "\n",
    "# Call the function to get the list of word indices\n",
    "filtered_words = words_to_filter(vocab, tfidf_vec.vocabulary_, text_tfidf, 3)\n",
    "\n",
    "# By converting filtered_words back to a list, we can use it to filter the columns in the text vector\n",
    "filtered_text = text_tfidf[:, list(filtered_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<617x1006 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2945 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Naive Bayes with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "np = GaussianNB()\n",
    "\n",
    "# Split the dataset according to the class distribution of category_desc, using the filtered_text vector\n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit the model to the training data\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print out the model's accuracy\n",
    "print(nb.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.98098724e-01 1.73593316e-03 9.43288311e-05 4.89462522e-05\n",
      " 1.04706853e-05 5.61289777e-06 2.79970917e-06 1.44536069e-06\n",
      " 9.76685744e-07 3.94374158e-07 2.15136165e-07 9.01993593e-08\n",
      " 6.27152353e-08]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Set up PCA and the X vector for diminsionality reduction\n",
    "pca = PCA()\n",
    "\n",
    "wine_X = wine.drop(\"Type\", axis=1)\n",
    "\n",
    "# Apply PCA to the wine dataset X vector\n",
    "transformed_X = pca.fit_transform(wine_X)\n",
    "\n",
    "# Look at the percentage of variance explained by the different components\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn =  GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = wine.dropna().Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "# Split the transformed X and the y labels into training and test sets\n",
    "X_wine_train, X_wine_test, y_wine_train, y_wine_test = train_test_split(transformed_X, y)\n",
    "\n",
    "# Fit knn to the training data\n",
    "knn.fit(X_wine_train, y_wine_train)\n",
    "\n",
    "# Score knn on the test data and print it out\n",
    "print(knn.score(X_wine_test, y_wine_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11/3/2011 19:21</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2004 19:05</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/25/2009 21:00</td>\n",
       "      <td>coon rapids</td>\n",
       "      <td>mn</td>\n",
       "      <td>us</td>\n",
       "      <td>cigar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green&amp;#44 red&amp;#44 and blue pulses of light tha...</td>\n",
       "      <td>12/12/2009</td>\n",
       "      <td>45.1200000</td>\n",
       "      <td>-93.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11/21/2002 05:45</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/19/2010 12:55</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date              city state country      type    seconds  \\\n",
       "0   11/3/2011 19:21         woodville    wi      us   unknown  1209600.0   \n",
       "1   10/3/2004 19:05         cleveland    oh      us    circle       30.0   \n",
       "2   9/25/2009 21:00       coon rapids    mn      us     cigar        0.0   \n",
       "3  11/21/2002 05:45          clemmons    nc      us  triangle      300.0   \n",
       "4   8/19/2010 12:55  calgary (canada)    ab      ca      oval        0.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "2              NaN  Green&#44 red&#44 and blue pulses of light tha...   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "\n",
       "     recorded         lat        long  \n",
       "0  12/12/2011  44.9530556  -92.291111  \n",
       "1  10/27/2004  41.4994444  -81.695556  \n",
       "2  12/12/2009  45.1200000  -93.287500  \n",
       "3  12/23/2002  36.0213889  -80.382222  \n",
       "4   8/24/2010   51.083333 -114.083333  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo = pd.read_csv('ufo_sightings_large.csv')\n",
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4935, 11)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4935 entries, 0 to 4934\n",
      "Data columns (total 11 columns):\n",
      "date              4935 non-null object\n",
      "city              4926 non-null object\n",
      "state             4516 non-null object\n",
      "country           4255 non-null object\n",
      "type              4776 non-null object\n",
      "seconds           4935 non-null float64\n",
      "length_of_time    4792 non-null object\n",
      "desc              4932 non-null object\n",
      "recorded          4935 non-null object\n",
      "lat               4935 non-null object\n",
      "long              4935 non-null float64\n",
      "dtypes: float64(2), object(9)\n",
      "memory usage: 424.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ufo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date               object\n",
       "city               object\n",
       "state              object\n",
       "country            object\n",
       "type               object\n",
       "seconds           float64\n",
       "length_of_time     object\n",
       "desc               object\n",
       "recorded           object\n",
       "lat                object\n",
       "long              float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "seconds           float64\n",
       "date       datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the column types\n",
    "display(ufo.dtypes)\n",
    "\n",
    "# Change the type of seconds to float\n",
    "ufo[\"seconds\"] = ufo['seconds'].astype('float')\n",
    "\n",
    "# Change the date column to type datetime\n",
    "ufo[\"date\"] = pd.to_datetime(ufo['date'])\n",
    "\n",
    "# Check the column types\n",
    "display(ufo[['seconds', 'date']].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_of_time    143\n",
      "state             419\n",
      "type              159\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check how many values are missing in the length_of_time, state, and type columns\n",
    "print(ufo[['length_of_time', 'state', 'type']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4283, 11)\n"
     ]
    }
   ],
   "source": [
    "# Keep only rows where length_of_time, state, and type are not null\n",
    "ufo_no_missing = ufo[\n",
    "        ufo['length_of_time'].notnull() & \n",
    "        ufo['state'].notnull() & \n",
    "        ufo['type'].notnull()\n",
    "]\n",
    "\n",
    "# Print out the shape of the new dataset\n",
    "print(ufo_no_missing.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting numbers from strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufo = ufo_no_missing.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.7152778</td>\n",
       "      <td>-117.156389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date              city state country      type    seconds  \\\n",
       "0 2011-11-03 19:21:00         woodville    wi      us   unknown  1209600.0   \n",
       "1 2004-10-03 19:05:00         cleveland    oh      us    circle       30.0   \n",
       "3 2002-11-21 05:45:00          clemmons    nc      us  triangle      300.0   \n",
       "4 2010-08-19 12:55:00  calgary (canada)    ab      ca      oval        0.0   \n",
       "5 2012-06-16 23:00:00         san diego    ca      us     light      600.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "5       10 minutes  Dancing lights that would fly around and then ...   \n",
       "\n",
       "     recorded         lat        long  \n",
       "0  12/12/2011  44.9530556  -92.291111  \n",
       "1  10/27/2004  41.4994444  -81.695556  \n",
       "3  12/23/2002  36.0213889  -80.382222  \n",
       "4   8/24/2010   51.083333 -114.083333  \n",
       "5    7/4/2012  32.7152778 -117.156389  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 weeks</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30sec.</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10 minutes</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    length_of_time  minutes\n",
       "0          2 weeks      2.0\n",
       "1           30sec.     30.0\n",
       "3  about 5 minutes      NaN\n",
       "4                2      2.0\n",
       "5       10 minutes     10.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def return_minutes(time_string):\n",
    "\n",
    "    # Use \\d+ to grab digits\n",
    "    pattern = re.compile(r\"\\d+\")\n",
    "    \n",
    "    # Use match on the pattern and column\n",
    "    num = re.match(pattern, time_string)\n",
    "    if num is not None:\n",
    "        return int(num.group(0))\n",
    "        \n",
    "# Apply the extraction to the length_of_time column\n",
    "ufo[\"minutes\"] = ufo_no_missing[\"length_of_time\"].apply(lambda row: return_minutes(row))\n",
    "\n",
    "# Take a look at the head of both of the columns\n",
    "ufo[['length_of_time', 'minutes']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying features for standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seconds    1.545212e+10\n",
       "long       4.119751e+02\n",
       "minutes    9.470577e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seconds    1.545212e+10\n",
      "minutes    9.470577e+02\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hakan/.pyenv/versions/miniconda3-latest/lib/python3.5/site-packages/ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Check the variance of the seconds and minutes columns\n",
    "print(ufo[['seconds','minutes']].var())\n",
    "\n",
    "# Log normalize the seconds column\n",
    "ufo[\"seconds_log\"] = np.log(ufo['seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>-92.291111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>-81.695556</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.401197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>-80.382222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.703782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>-114.083333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.7152778</td>\n",
       "      <td>-117.156389</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.396930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date              city state country      type    seconds  \\\n",
       "0 2011-11-03 19:21:00         woodville    wi      us   unknown  1209600.0   \n",
       "1 2004-10-03 19:05:00         cleveland    oh      us    circle       30.0   \n",
       "3 2002-11-21 05:45:00          clemmons    nc      us  triangle      300.0   \n",
       "4 2010-08-19 12:55:00  calgary (canada)    ab      ca      oval        0.0   \n",
       "5 2012-06-16 23:00:00         san diego    ca      us     light      600.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "5       10 minutes  Dancing lights that would fly around and then ...   \n",
       "\n",
       "     recorded         lat        long  minutes  seconds_log  \n",
       "0  12/12/2011  44.9530556  -92.291111      2.0    14.005800  \n",
       "1  10/27/2004  41.4994444  -81.695556     30.0     3.401197  \n",
       "3  12/23/2002  36.0213889  -80.382222      NaN     5.703782  \n",
       "4   8/24/2010   51.083333 -114.083333      2.0         -inf  \n",
       "5    7/4/2012  32.7152778 -117.156389     10.0     6.396930  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6312000.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.seconds.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Use Pandas to encode us values as 1 and others as 0\n",
    "ufo[\"country_enc\"] = ufo[\"country\"].apply(lambda row: 1 if row == 'us' else 0)\n",
    "\n",
    "# Print the number of unique type values\n",
    "print(len(ufo.type.unique()))\n",
    "\n",
    "# Create a one-hot encoded set of the type values\n",
    "type_set = pd.get_dummies(ufo.type)\n",
    "\n",
    "# Concatenate this set back to the ufo DataFrame\n",
    "ufo = pd.concat([ufo, type_set], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>type</th>\n",
       "      <th>seconds</th>\n",
       "      <th>length_of_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>recorded</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>flash</th>\n",
       "      <th>formation</th>\n",
       "      <th>light</th>\n",
       "      <th>other</th>\n",
       "      <th>oval</th>\n",
       "      <th>rectangle</th>\n",
       "      <th>sphere</th>\n",
       "      <th>teardrop</th>\n",
       "      <th>triangle</th>\n",
       "      <th>unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-11-03 19:21:00</td>\n",
       "      <td>woodville</td>\n",
       "      <td>wi</td>\n",
       "      <td>us</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1209600.0</td>\n",
       "      <td>2 weeks</td>\n",
       "      <td>Red blinking objects similar to airplanes or s...</td>\n",
       "      <td>12/12/2011</td>\n",
       "      <td>44.9530556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-10-03 19:05:00</td>\n",
       "      <td>cleveland</td>\n",
       "      <td>oh</td>\n",
       "      <td>us</td>\n",
       "      <td>circle</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30sec.</td>\n",
       "      <td>Many fighter jets flying towards UFO</td>\n",
       "      <td>10/27/2004</td>\n",
       "      <td>41.4994444</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-11-21 05:45:00</td>\n",
       "      <td>clemmons</td>\n",
       "      <td>nc</td>\n",
       "      <td>us</td>\n",
       "      <td>triangle</td>\n",
       "      <td>300.0</td>\n",
       "      <td>about 5 minutes</td>\n",
       "      <td>It was a large&amp;#44 triangular shaped flying ob...</td>\n",
       "      <td>12/23/2002</td>\n",
       "      <td>36.0213889</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-08-19 12:55:00</td>\n",
       "      <td>calgary (canada)</td>\n",
       "      <td>ab</td>\n",
       "      <td>ca</td>\n",
       "      <td>oval</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A white spinning disc in the shape of an oval.</td>\n",
       "      <td>8/24/2010</td>\n",
       "      <td>51.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-06-16 23:00:00</td>\n",
       "      <td>san diego</td>\n",
       "      <td>ca</td>\n",
       "      <td>us</td>\n",
       "      <td>light</td>\n",
       "      <td>600.0</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>Dancing lights that would fly around and then ...</td>\n",
       "      <td>7/4/2012</td>\n",
       "      <td>32.7152778</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date              city state country      type    seconds  \\\n",
       "0 2011-11-03 19:21:00         woodville    wi      us   unknown  1209600.0   \n",
       "1 2004-10-03 19:05:00         cleveland    oh      us    circle       30.0   \n",
       "3 2002-11-21 05:45:00          clemmons    nc      us  triangle      300.0   \n",
       "4 2010-08-19 12:55:00  calgary (canada)    ab      ca      oval        0.0   \n",
       "5 2012-06-16 23:00:00         san diego    ca      us     light      600.0   \n",
       "\n",
       "    length_of_time                                               desc  \\\n",
       "0          2 weeks  Red blinking objects similar to airplanes or s...   \n",
       "1           30sec.               Many fighter jets flying towards UFO   \n",
       "3  about 5 minutes  It was a large&#44 triangular shaped flying ob...   \n",
       "4                2     A white spinning disc in the shape of an oval.   \n",
       "5       10 minutes  Dancing lights that would fly around and then ...   \n",
       "\n",
       "     recorded         lat   ...     flash  formation  light  other  oval  \\\n",
       "0  12/12/2011  44.9530556   ...         0          0      0      0     0   \n",
       "1  10/27/2004  41.4994444   ...         0          0      0      0     0   \n",
       "3  12/23/2002  36.0213889   ...         0          0      0      0     0   \n",
       "4   8/24/2010   51.083333   ...         0          0      0      0     1   \n",
       "5    7/4/2012  32.7152778   ...         0          0      1      0     0   \n",
       "\n",
       "   rectangle  sphere  teardrop  triangle  unknown  \n",
       "0          0       0         0         0        1  \n",
       "1          0       0         0         0        0  \n",
       "3          0       0         0         1        0  \n",
       "4          0       0         0         0        0  \n",
       "5          0       0         0         0        0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features from dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2011-11-03 19:21:00\n",
      "1   2004-10-03 19:05:00\n",
      "3   2002-11-21 05:45:00\n",
      "4   2010-08-19 12:55:00\n",
      "5   2012-06-16 23:00:00\n",
      "Name: date, dtype: datetime64[ns]\n",
      "                    date  month  year\n",
      "0    2011-11-03 19:21:00     11  2011\n",
      "1    2004-10-03 19:05:00     10  2004\n",
      "3    2002-11-21 05:45:00     11  2002\n",
      "4    2010-08-19 12:55:00      8  2010\n",
      "5    2012-06-16 23:00:00      6  2012\n",
      "6    2009-07-12 21:30:00      7  2009\n",
      "7    2008-10-20 18:30:00     10  2008\n",
      "8    2013-06-09 00:00:00      6  2013\n",
      "9    2013-04-26 23:27:00      4  2013\n",
      "10   2013-09-13 20:30:00      9  2013\n",
      "11   2013-02-13 21:00:00      2  2013\n",
      "12   2012-05-20 00:00:00      5  2012\n",
      "13   2011-06-02 22:05:00      6  2011\n",
      "14   1999-09-01 20:30:00      9  1999\n",
      "15   2013-09-04 21:50:00      9  2013\n",
      "16   2011-05-24 22:15:00      5  2011\n",
      "17   1993-05-15 02:30:00      5  1993\n",
      "18   2009-06-22 21:00:00      6  2009\n",
      "19   2008-09-22 17:40:00      9  2008\n",
      "20   1984-11-15 18:00:00     11  1984\n",
      "21   2010-03-11 19:00:00      3  2010\n",
      "22   1931-02-15 14:00:00      2  1931\n",
      "23   1999-12-09 21:50:00     12  1999\n",
      "25   2010-10-27 18:20:00     10  2010\n",
      "26   1999-02-02 06:39:00      2  1999\n",
      "27   2003-04-24 21:55:00      4  2003\n",
      "28   2002-06-13 22:15:00      6  2002\n",
      "29   2006-04-24 00:36:00      4  2006\n",
      "30   2008-03-27 21:35:00      3  2008\n",
      "31   2009-06-19 01:00:00      6  2009\n",
      "...                  ...    ...   ...\n",
      "4900 2004-10-08 18:00:00     10  2004\n",
      "4901 2000-01-01 17:00:00      1  2000\n",
      "4904 2010-06-24 22:00:00      6  2010\n",
      "4905 2005-10-07 20:00:00     10  2005\n",
      "4906 2003-07-11 02:00:00      7  2003\n",
      "4907 2005-10-02 02:00:00     10  2005\n",
      "4908 2013-08-12 05:00:00      8  2013\n",
      "4910 2007-07-10 22:30:00      7  2007\n",
      "4911 1999-12-14 07:45:00     12  1999\n",
      "4912 2000-03-24 18:00:00      3  2000\n",
      "4914 2011-12-01 07:30:00     12  2011\n",
      "4915 2014-01-01 21:00:00      1  2014\n",
      "4916 1999-08-09 20:18:00      8  1999\n",
      "4917 1969-04-21 16:30:00      4  1969\n",
      "4918 2004-08-16 02:00:00      8  2004\n",
      "4920 2004-11-05 05:00:00     11  2004\n",
      "4921 2002-08-16 19:45:00      8  2002\n",
      "4922 1999-01-25 01:15:00      1  1999\n",
      "4923 2007-02-11 19:25:00      2  2007\n",
      "4924 2011-11-16 20:13:00     11  2011\n",
      "4925 2006-12-16 07:20:00     12  2006\n",
      "4926 2002-08-20 23:10:00      8  2002\n",
      "4927 2013-07-04 21:00:00      7  2013\n",
      "4928 2008-11-10 00:30:00     11  2008\n",
      "4929 1998-06-25 22:18:00      6  1998\n",
      "4930 2000-07-05 19:30:00      7  2000\n",
      "4931 2008-03-18 22:00:00      3  2008\n",
      "4932 2005-06-15 02:30:00      6  2005\n",
      "4933 1991-11-01 03:00:00     11  1991\n",
      "4934 2005-12-10 18:00:00     12  2005\n",
      "\n",
      "[4283 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Look at the first 5 rows of the date column\n",
    "print(ufo.date.head())\n",
    "\n",
    "# Extract the month from the date column\n",
    "ufo[\"month\"] = ufo[\"date\"].dt.month\n",
    "\n",
    "# Extract the year from the date column\n",
    "ufo[\"year\"] = ufo[\"date\"].dt.year\n",
    "\n",
    "# Take a look at the head of all three columns\n",
    "print(ufo[['date', 'month', 'year']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Red blinking objects similar to airplanes or s...\n",
      "1                 Many fighter jets flying towards UFO\n",
      "3    It was a large&#44 triangular shaped flying ob...\n",
      "4       A white spinning disc in the shape of an oval.\n",
      "5    Dancing lights that would fly around and then ...\n",
      "Name: desc, dtype: object\n",
      "(4283, 5754)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the head of the desc field\n",
    "print(ufo['desc'].head())\n",
    "\n",
    "# Create the tfidf vectorizer object\n",
    "vec = TfidfVectorizer()\n",
    "\n",
    "# Use vec's fit_transform method on the desc field\n",
    "desc_tfidf = vec.fit_transform(ufo.desc)\n",
    "\n",
    "# Look at the number of columns this creates\n",
    "print(desc_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the ideal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {v:k for k,v in vec.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds</th>\n",
       "      <th>seconds_log</th>\n",
       "      <th>minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seconds</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.174331</td>\n",
       "      <td>-0.009932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seconds_log</th>\n",
       "      <td>0.174331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minutes</th>\n",
       "      <td>-0.009932</td>\n",
       "      <td>0.111460</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              seconds  seconds_log   minutes\n",
       "seconds      1.000000     0.174331 -0.009932\n",
       "seconds_log  0.174331     1.000000  0.111460\n",
       "minutes     -0.009932     0.111460  1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the correlation between the seconds, seconds_log, and minutes columns\n",
    "display(ufo[['seconds', 'seconds_log', 'minutes']].corr())\n",
    "\n",
    "# Make a list of features to drop\n",
    "to_drop = ['city', 'country', 'lat','long', 'state', 'seconds', 'minutes', 'date', 'desc', 'length_of_time', 'recorded']\n",
    "\n",
    "# Drop those features\n",
    "ufo_dropped = ufo.drop(to_drop, axis=1)\n",
    "\n",
    "# Let's also filter some words out of the text vector we created\n",
    "filtered_words = words_to_filter(vocab, vec.vocabulary_, desc_tfidf, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the UFO dataset, part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'seconds_log', 'country_enc', 'changing', 'chevron', 'cigar',\n",
       "       'circle', 'cone', 'cross', 'cylinder', 'diamond', 'disk', 'egg',\n",
       "       'fireball', 'flash', 'formation', 'light', 'other', 'oval', 'rectangle',\n",
       "       'sphere', 'teardrop', 'triangle', 'unknown', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufo_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ufo_dropped[['seconds_log', 'changing', 'chevron', 'cigar', 'circle', 'cone',\n",
    "       'cross', 'cylinder', 'diamond', 'disk', 'egg', 'fireball', 'flash',\n",
    "       'formation', 'light', 'other', 'oval', 'rectangle', 'sphere',\n",
    "       'teardrop', 'triangle', 'unknown', 'month', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ufo_dropped['country_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4283, 24), (4283,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the X and y sets using train_test_split, setting stratify=y\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, stratify=y)\n",
    "\n",
    "# Fit knn to the training sets\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of knn on the test sets\n",
    "print(knn.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the UFO dataset, part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the list of filtered words we created to filter the text vector\n",
    "filtered_text = desc_tfidf[:, list(filtered_words)]\n",
    "\n",
    "# Split the X and y sets using train_test_split, setting stratify=y \n",
    "train_X, test_X, train_y, test_y = train_test_split(filtered_text.toarray(), y, stratify=y)\n",
    "\n",
    "# Fit nb to the training sets\n",
    "nb.fit(train_X, train_y)\n",
    "\n",
    "# Print the score of nb on the test sets\n",
    "print(nb.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a clear case where iteration would be necessary to figure out what subset of text improves the model, and if perhaps any of the other features are useful in predicting type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
