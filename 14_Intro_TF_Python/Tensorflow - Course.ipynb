{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Introduction to TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Import constant from TensorFlow\n",
    "from tensorflow import constant\n",
    "\n",
    "# Convert the credit_numpy array into a tensorflow constant\n",
    "credit_constant = constant(credit_numpy)\n",
    "\n",
    "# Print constant datatype\n",
    "print('The datatype is:', credit_constant.dtype)\n",
    "\n",
    "# Print constant shape\n",
    "print('The shape is:', credit_constant.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 1-dimensional variable A1\n",
    "A1 = tf.Variable([1, 2, 3, 4])\n",
    "\n",
    "# Print the variable A1\n",
    "print(A1)\n",
    "\n",
    "# Convert A1 to a numpy array and assign it to B1\n",
    "B1 = A1.numpy()\n",
    "\n",
    "# Print B1\n",
    "print(B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing element-wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import constant, multiply, ones_like\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tensors A1 and A23 as constants\n",
    "A1 = constant([1, 2, 3, 4])\n",
    "A23 = constant([[1, 2, 3], [1, 6, 4]])\n",
    "\n",
    "# Define B1 and B23 to have the correct shape\n",
    "B1 = ones_like(A1)\n",
    "B23 = ones_like(A23)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "C1 = multiply(A1, B1)\n",
    "C23 = multiply(A23, B23)\n",
    "\n",
    "# Print the tensors C1 and C23\n",
    "print('C1: {}'.format(C1.numpy()))\n",
    "print('C23: {}'.format(C23.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions with matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features, params, and bill as constants\n",
    "features = constant([[2, 24], [2, 26], [2, 57], [1, 37]])\n",
    "params = constant([[1000], [150]])\n",
    "bill = constant([[3913], [2682], [8617], [64400]])\n",
    "\n",
    "# Compute billpred using features and params\n",
    "billpred = matmul(features, params)\n",
    "\n",
    "# Compute and print the error\n",
    "error = bill - billpred\n",
    "print(error.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the grayscale image tensor into a vector\n",
    "gray_vector = reshape(gray_tensor, (28*28, 1))\n",
    "\n",
    "# Reshape the color image tensor into a vector\n",
    "color_vector = reshape(color_tensor, (28*28*3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing with gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(x0):\n",
    "    # Define x as a variable with an initial value of x0\n",
    "    x = Variable(x0)\n",
    "    with GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        # Define y using the multiply operation\n",
    "        y = multiply(x,x)\n",
    "    # Return the gradient of y with respect to x\n",
    "    return tape.gradient(y, x).numpy()\n",
    "\n",
    "# Compute and print gradients at x = -1, 1, and 0\n",
    "print(compute_gradient(-1.0))\n",
    "print(compute_gradient(1.0))\n",
    "print(compute_gradient(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape model from a 1x3 to a 3x1 tensor\n",
    "model = reshape(model, (1*3, 1))\n",
    "\n",
    "# Multiply letter by model\n",
    "output = matmul(letter, model)\n",
    "\n",
    "# Sum over output and print prediction using the numpy method\n",
    "prediction = reduce_sum(output)\n",
    "print(prediction.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas under the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the path to a string variable named data_path\n",
    "data_path = 'kc_house_data.csv'\n",
    "\n",
    "# Load the dataset as a dataframe named housing\n",
    "housing = pd.read_csv(data_path)\n",
    "\n",
    "# Print the price column of housing\n",
    "print(housing.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.arrapy(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras module from tensorflow\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "# Compute the mean squared error (mse)\n",
    "loss = keras.losses.mse(price, predictions)\n",
    "\n",
    "# Print the mean squared error (mse)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras module from tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mae(price, predictions)\n",
    "\n",
    "# Print the mean absolute error (mae)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = Variable(1.0, float32)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "    return scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "    # Compute the predicted values\n",
    "    predictions = model(scalar, features)\n",
    "    \n",
    "    # Return the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features = size_log):\n",
    "    return intercept+features * slope\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Return the mean squared error loss\n",
    "    return keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an adam optimizer\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(500):\n",
    "    # Apply minimize, pass the loss function, and supply the variables\n",
    "    opt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "    # Print every 100th value of the loss\n",
    "    if j % 100 == 0:\n",
    "        print(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear regression model\n",
    "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
    "    return params[0] + feature1*params[1] + feature2*params[2]\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
    "    # Set the predicted values\n",
    "    predictions = linear_regression(params, feature1, feature2)\n",
    "  \n",
    "    # Use the mean absolute error loss\n",
    "    return keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "    opt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "    print_results(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to batch train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = Variable(10.0, float32)\n",
    "slope = Variable(0.5, float32)\n",
    "\n",
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "    # Define the predicted values\n",
    "    return features*slope + intercept\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    # Define the predicted values\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Define the MSE loss\n",
    "    return keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Notice that we did not use default argument values for the input data, features and targets. This is because the input data has not been defined in advance. Instead, with batch training, we will load it during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a linear model in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "    size_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "    # Extract the price values for the current batch\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Complete the loss, fill in the variable list, and minimize\n",
    "    opt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The linear algebra of dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias1 = Variable(1.0)\n",
    "weights1 = Variable(ones((3, 2)))\n",
    "\n",
    "product1 = matmul(borrower_features, weights1)\n",
    "\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = Variable(1.0)\n",
    "weights2 = Variable(ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = matmul(dense1, weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = keras.activations.sigmoid(product2 + weights2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The low-level approach with multiple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the product of borrower_features and weights1\n",
    "products1 = matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
    "print('\\n shape of weights1: ', weights1.shape)\n",
    "print('\\n shape of bias1: ', bias1.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the dense layer operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input layer from features\n",
    "inputs = constant(bill_amounts, np.float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(3, activation='relu')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print error for first five examples\n",
    "error = default[:5] - outputs.numpy()[:5]\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct input layer from borrower features\n",
    "inputs = constant(borrower_features, float32)\n",
    "\n",
    "# Define first dense layer\n",
    "dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "\n",
    "# Define second dense layer\n",
    "dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
    "\n",
    "# Define output layer\n",
    "outputs = keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "\n",
    "# Print first five predictions\n",
    "print(outputs.numpy()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dangers of local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = Variable(6.0,float32)\n",
    "x_2 = Variable(0.3,float32)\n",
    "\n",
    "# Define the optimization operation\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for j in range(100):\n",
    "    # Perform minimization using the loss function and x_1\n",
    "    opt.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    # Perform minimization using the loss function and x_2\n",
    "    opt.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize x_1 and x_2\n",
    "x_1 = Variable(0.05,float32)\n",
    "x_2 = Variable(0.05,float32)\n",
    "\n",
    "# Define the optimization operation for opt_1 and opt_2\n",
    "opt_1 = keras.optimizers.RMSprop(learning_rate=.01, momentum=.99)\n",
    "opt_2 = keras.optimizers.RMSprop(learning_rate=.01, momentum=.0)\n",
    "\n",
    "for j in range(100):\n",
    "\topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "    # Define the minimization operation for opt_2\n",
    "\topt_2.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# Print x_1 and x_2 as numpy arrays\n",
    "print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layer 1 weights\n",
    "w1 = Variable(random.normal([23, 7]))\n",
    "\n",
    "# Initialize the layer 1 bias\n",
    "b1 = Variable(ones([7]))\n",
    "\n",
    "# Define the layer 2 weights\n",
    "w2 = Variable(random.normal([7, 1]))\n",
    "\n",
    "# Define the layer 2 bias\n",
    "b2 = Variable(.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = borrower_features):\n",
    "    # Apply relu activation functions to layer 1\n",
    "    layer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "    # Apply dropout\n",
    "    dropout = keras.layers.Dropout(.25)(layer1)\n",
    "\n",
    "    return keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "    predictions = model(w1, b1, w2, b2)\n",
    "    # Pass targets and predictions to the cross entropy loss\n",
    "    return keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(w1, b1, w2, b2, features = borrower_features):\n",
    "    # Apply relu activation functions to layer 1\n",
    "    layer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "    # Apply dropout\n",
    "    dropout = keras.layers.Dropout(0.25)(layer1)\n",
    "\n",
    "    return keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "    predictions = model(w1, b1, w2, b2)\n",
    "    # Pass targets and predictions to the cross entropy loss\n",
    "    return keras.losses.binary_crossentropy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training neural networks with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "for j in range(100):\n",
    "    # Complete the optimizer\n",
    "    opt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
    "                                var_list=[w1, b1, w2, b2])\n",
    "\n",
    "# Make predictions with model\n",
    "model_predictions = model(w1, b1, w2, b2, test_features)\n",
    "\n",
    "# Construct the confusion matrix\n",
    "confusion_matrix(test_targets, model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "High Level APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequential model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Keras sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the second dense layer\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "model.add(keras.layers.Dense(16, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Apply dropout to the first layer's output\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a multiple input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model 1, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m1_layer1 = keras.layers.Dense(12, activation='sigmoid')(m1_inputs)\n",
    "m1_layer2 = keras.layers.Dense(4, activation='softmax')(m1_layer1)\n",
    "\n",
    "# For model 2, pass the input layer to layer 1 and layer 1 to layer 2\n",
    "m2_layer1 = keras.layers.Dense(12, activation='relu')(m2_inputs)\n",
    "m2_layer2 = keras.layers.Dense(4, activation='softmax')(m2_layer1)\n",
    "\n",
    "# Merge model outputs and define a functional model\n",
    "merged = keras.layers.add([m1_layer2, m2_layer2])\n",
    "model = keras.Model(inputs=[m1_inputs, m2_inputs], outputs=merged)\n",
    "\n",
    "# Print a model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define a hidden layer\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Define the output layer\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile('SGD', loss='categorical_crossentropy')\n",
    "\n",
    "# Complete the fitting operation\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and validation with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(32, activation='sigmoid', input_shape=(784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Set the optimizer, loss function, and metrics\n",
    "model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add the number of epochs and the validation split\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=10, validation_split=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Define the first layer\n",
    "model.add(keras.layers.Dense(1024, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Add activation function to classifier\n",
    "model.add(keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# Finish the model compilation\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.01), \n",
    "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Complete the model fit operation\n",
    "model.fit(sign_language_features, sign_language_labels, epochs=200, validation_split=.5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If val_loss started to increase before the training process was terminated, then we may have overfitted. When this happens, you will want to try decreasing the number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the small model using the train data\n",
    "small_train = small_model.evaluate(train_features, train_labels)\n",
    "\n",
    "# Evaluate the small model using the test data\n",
    "small_test = small_model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Evaluate the large model using the train data\n",
    "large_train = large_model.evaluate(train_features, train_labels)\n",
    "\n",
    "# Evaluate the large model using the test data\n",
    "large_test = large_model.evaluate(test_features, test_labels)\n",
    "\n",
    "# Print losses\n",
    "print('\\n Small - Train: {}, Test: {}'.format(small_train, small_test))\n",
    "print('Large - Train: {}, Test: {}'.format(large_train, large_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing to train with Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns for bedrooms and bathrooms\n",
    "bedrooms = feature_column.numeric_column(\"bedrooms\")\n",
    "bathrooms = feature_column.numeric_column('bathrooms')\n",
    "\n",
    "# Define the list of feature columns\n",
    "feature_list = [bedrooms, bathrooms]\n",
    "\n",
    "def input_fn():\n",
    "    # Define the labels\n",
    "    labels = np.array(housing['price'])\n",
    "    # Define the features\n",
    "    features = {'bedrooms': np.array(housing['bedrooms']), \n",
    "                'bathrooms': np.array(housing['bathrooms'])}\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and set the number of steps\n",
    "model = estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
    "model.train(input_fn, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model and set the number of steps\n",
    "model = estimator.LinearRegressor(feature_columns=feature_list,)\n",
    "model.train(input_fn, steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb_lgbm",
   "language": "python",
   "name": "lgbm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
